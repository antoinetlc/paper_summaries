<p align="center">
<b>Image-to-Image Translation with Conditional Adversarial Nets</b><br>
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros<br>
CVPR 2017<br>
<a href="https://phillipi.github.io/pix2pix/">Link to paper</a>
</p>
![Examples of image to image translation](https://github.com/antoinetlc/paper_summaries/blob/master/Papers/Image-to-Image_Translation_with_Conditional_Adversarial_Nets_Isola_et_al_CVPR17/Images/teaser.jpg "Examples of image to image translation")

### Context 

* The paper tackles the problem of image translation, i.e mapping an image to another image automatically without user intervention, using a set of paired images (input, target). Such problem often arises in computer graphics and vision. An example could be mapping a sketch to a drawing or changing a satellite image to a map.

### Novelty and contributions :

* Provide a general framework for image to image translation using conditonal generative adversarial networks (cGAN) that produces sharp results and works on a large variety of problems.

* Study the influence of the different architectures of the discriminator and generator and compare how changing the loss function affect the results.

### How was it solved ?



### Results
